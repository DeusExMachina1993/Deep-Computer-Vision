{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeusExMachina1993/Deep-Computer-Vision/blob/master/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8QJK1sietQq",
        "colab_type": "text"
      },
      "source": [
        "Project 1:**Multi-layer NN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOlqLTcse6Dn",
        "colab_type": "text"
      },
      "source": [
        "Q.Use MNIST dataset for multi-class classification. Change the following parameters and report recognition accuracy and time on train, test, and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9a3aBlTkP23",
        "colab_type": "text"
      },
      "source": [
        "a- number of hidden layers\n",
        "b- number of neurons per layer\n",
        "c- optimization algorithm\n",
        "d- loss function\n",
        "e- number of epochs\n",
        "f- batch size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPpz1UosgbCR",
        "colab_type": "text"
      },
      "source": [
        "**Classifying Handwritten Digits with Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqHomGFzjt--",
        "colab_type": "text"
      },
      "source": [
        "![img](https://www.tensorflow.org/images/MNIST.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY90Gy74keJR",
        "colab_type": "text"
      },
      "source": [
        "The process will be broken down into the following steps:\n",
        "\n",
        "1.   Load and visualize the data\n",
        "2.   Define a neural network\n",
        "3.   Train the model\n",
        "4.   Evaluate the performance \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtS_qR5HliOG",
        "colab_type": "text"
      },
      "source": [
        "Load necessary Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGVTXlf2kd1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMeexpO-e_J0",
        "colab_type": "text"
      },
      "source": [
        "1.Load and visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP8-qSHBlwxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkXjoF_Al2Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape grayscale images to have a single channel\n",
        "width, height, channels = x_train.shape[1], x_train.shape[2], 1\n",
        "x_train = x_train.reshape((x_train.shape[0], width, height, channels))\n",
        "x_test = x_test.reshape((x_test.shape[0], width, height, channels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTJVZ0VSmOcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMfRCaL6mxXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode target values\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhg-dnMPtVSz",
        "colab_type": "text"
      },
      "source": [
        "2.Define a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnpnpmF15TYZ",
        "colab_type": "text"
      },
      "source": [
        "Expriement 1:\n",
        "\n",
        "\n",
        "```\n",
        "a- number of hidden layers=1\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "b- number of neurons per layer=64\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "c- optimization algorithm=SGD\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "d- loss function= cross entropy loss function\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "e- number of epochs=5\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "f- batch size=32\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "g- activation function=Relu\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBa5mK5Modxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4wIpOs9vwXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(784,activation=\"relu\"))#input layer\n",
        "model.add(Dense(64,activation=\"relu\"))#hidden layer\n",
        "model.add(Dense(10,activation=\"softmax\"))#output layer layer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eAILvZoA87W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.sgd(),loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCqdW6YyA7lN",
        "colab_type": "text"
      },
      "source": [
        "3.Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzbRiwfMBMGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "793d32a6-e173-46cd-d122-456b97d25c0c"
      },
      "source": [
        "# train model\n",
        "train = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32, epochs=5,\n",
        "    verbose=1, validation_split=0.1\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-db72b9953ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have 4 dimensions, but got array with shape (60000, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhUrNkmB-gW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68a1d6c0-8951-4995-b489-5c0dcdd6b234"
      },
      "source": [
        "model.summary"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f787986d710>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLQ8lAbDTf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}